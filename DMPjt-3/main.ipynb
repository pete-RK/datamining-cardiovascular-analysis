{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2555f39",
   "metadata": {},
   "source": [
    "# Importing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "123fb2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import datetime as dt\n",
    "import scipy as sp\n",
    "import scipy.fftpack\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63992cac",
   "metadata": {},
   "source": [
    "# Reading csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "898cbb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading CMGData csv file\n",
    "df = pd.read_csv('CGMData.csv', low_memory=False)\n",
    "df['DateTime'] = (df['Date'] + ' ' + df['Time'])\n",
    "df['DateTime'] = pd.to_datetime(df['DateTime'])\n",
    "\n",
    "\n",
    "#reading Insulin csv file\n",
    "dfI = pd.read_csv('InsulinData.csv', low_memory=False)\n",
    "dfI['DateTime'] = (dfI['Date'] + ' ' + dfI['Time'])\n",
    "dfI['DateTime'] = pd.to_datetime(dfI['DateTime'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3266fe66",
   "metadata": {},
   "source": [
    "# Extracting time series from Insulin.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "351f92b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Day time range\n",
    "dayTime_str = '02:00:00'\n",
    "timeLimit = pd.to_timedelta(dayTime_str)\n",
    "\n",
    "#Extarcting Meal times from Insulin.CSV\n",
    "dfI_Meals_Taken = dfI.loc[dfI['BWZ Carb Input (grams)'] > 0]\n",
    "mealTime_List = dfI_Meals_Taken['DateTime'].tolist()\n",
    "\n",
    "#Extracting valid Meal Times from Insulin.CSV\n",
    "def extractMealTimeInsulin(mealTime_List):\n",
    "    mealTime_Valid = [mealTime_List[0]]\n",
    "    for i in range(len(mealTime_List) - 1):\n",
    "        diff = mealTime_List[i] - mealTime_List[i+1]\n",
    "        if diff > timeLimit:\n",
    "            mealTime_Valid.append(mealTime_List[i+1])\n",
    "    return mealTime_Valid\n",
    "\n",
    "#Defining valid times for both insulin files\n",
    "mealTime_Valid = extractMealTimeInsulin(mealTime_List)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754cf36d",
   "metadata": {},
   "source": [
    "# Finding max and min carb values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff3b4132",
   "metadata": {},
   "outputs": [],
   "source": [
    "carbInput = []\n",
    "carbInputTime = []\n",
    "\n",
    "def carbinputvalueExtraciton(mealTime_Valid):\n",
    "    for i in range(len(mealTime_Valid)):\n",
    "        dfI_carbinput = dfI.loc[dfI['DateTime'] == mealTime_Valid[i]]\n",
    "        dfI_carbinput = dfI_carbinput[(dfI_carbinput['BWZ Carb Input (grams)'] > 0) & (dfI_carbinput['BWZ Carb Input (grams)'] > 2)]\n",
    "        dfI_carbinput = dfI_carbinput[[\"BWZ Carb Input (grams)\", \"DateTime\"]]\n",
    "        carbInputval = dfI_carbinput['BWZ Carb Input (grams)'].values[0]\n",
    "        carbInputTimeval = dfI_carbinput['DateTime'].values[0]\n",
    "        carbInput.append(carbInputval)\n",
    "        carbInputTime.append(carbInputTimeval)\n",
    "    return carbInput, carbInputTime\n",
    "\n",
    "carbInput, carbInputTime = carbinputvalueExtraciton(mealTime_Valid)\n",
    "\n",
    "#Extracting min and max from carbInput list\n",
    "carbMin = int(min(carbInput))\n",
    "carbMax = int(max(carbInput))\n",
    "\n",
    "data1 =[]\n",
    "for i in range(len(carbInputTime)):\n",
    "    data1.append({\n",
    "    'Carb Input' : carbInput[i],\n",
    "    'DateTime' : carbInputTime[i]})\n",
    "\n",
    "dfI_carbinput = pd.DataFrame(data1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2338cae3",
   "metadata": {},
   "source": [
    "# Extracting Valid TimeSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6beb3b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting time series\n",
    "def extractingValidTimeSeries(mealTime_Valid):\n",
    "    timeCMG_Valid = []\n",
    "    timeCMG_Valid_Extra30 = []\n",
    "    timeCMG_ValidStart = []\n",
    "    for i in mealTime_Valid:\n",
    "        df_time = df.loc[df['DateTime'] >= i]\n",
    "        time_2 = df_time['DateTime'].iloc[-1]\n",
    "        timeCMG_ValidStart.append(time_2)\n",
    "        time_3, time_4 = time_2 - pd.Timedelta(minutes = 30), time_2 + pd.Timedelta(minutes = 120)\n",
    "        timeCMG_Valid.append(time_4)\n",
    "        timeCMG_Valid_Extra30.append(time_3)\n",
    "    return timeCMG_Valid, timeCMG_Valid_Extra30, timeCMG_ValidStart\n",
    "\n",
    "timeCMG_Valid, timeCMG_Valid_Extra30, timeCMG_ValidStart = extractingValidTimeSeries(mealTime_Valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1627324",
   "metadata": {},
   "source": [
    "# Extarcting Meal Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "189ea124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractingMealMatrix(timeCMG_Valid, timeCMG_Valid_Extra30, timeCMG_ValidStart):\n",
    "    meal_Matrix = []\n",
    "    time_Matrix = []\n",
    "    #Recorded true time\n",
    "    trueMeal_Matrix = []\n",
    "    trueTime_Matrix = []\n",
    "    for i in range(len(timeCMG_Valid)):  \n",
    "        df_valid = df.loc[df['DateTime'].between(timeCMG_Valid_Extra30[i], timeCMG_Valid[i], inclusive='both')]\n",
    "        df_trueMeal = df.loc[df['DateTime'].between(timeCMG_ValidStart[i], timeCMG_Valid[i], inclusive='both')]\n",
    "        df_valid1 = df_valid.loc[df_valid['Sensor Glucose (mg/dL)'] >= 0]\n",
    "        df_trueMeal1 = df_trueMeal.loc[df_trueMeal['Sensor Glucose (mg/dL)'] >= 0]\n",
    "    \n",
    "        time_List = df_valid1['DateTime'].tolist()\n",
    "        meal_List = df_valid1['Sensor Glucose (mg/dL)'].tolist()  \n",
    "        trueTime_List = df_trueMeal1['DateTime'].tolist()\n",
    "        trueMeal_List = df_trueMeal1['Sensor Glucose (mg/dL)'].tolist()\n",
    "        if sum(trueMeal_List) > 0 and len(meal_List) >= 30:\n",
    "            trueTime_Matrix.append(trueTime_List)\n",
    "            trueMeal_Matrix.append(trueMeal_List)\n",
    "            time_Matrix.append(time_List)\n",
    "            meal_Matrix.append(meal_List)\n",
    "    return meal_Matrix, time_Matrix, trueMeal_Matrix, trueTime_Matrix\n",
    "\n",
    "meal_Matrix, time_Matrix, trueMeal_Matrix, trueTime_Matrix = extractingMealMatrix(timeCMG_Valid, timeCMG_Valid_Extra30, timeCMG_ValidStart)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8356aa",
   "metadata": {},
   "source": [
    "# Bin Values based on time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdf14685",
   "metadata": {},
   "outputs": [],
   "source": [
    "carbMatrix = []\n",
    "for j in trueTime_Matrix:\n",
    "    dfI_carbTemp = dfI_carbinput.loc[dfI_carbinput['DateTime'] <= j[-1]]\n",
    "    dfI_carbTemp = dfI_carbTemp.iloc[0]\n",
    "    carbInputval = dfI_carbTemp['Carb Input']\n",
    "    carbMatrix.append(carbInputval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb360ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 3, 0, 1, 4, 0, 1, 2, 0, 0, 1, 2, 0, 3, 2, 2, 0, 2, 0, 1, 2, 4, 0, 2, 0, 1, 0, 4, 0, 0, 4, 0, 0, 2, 1, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 2, 1, 1, 4, 1, 0, 1, 2, 1, 0, 1, 3, 1, 0, 2, 0, 0, 1, 2, 2, 2, 1, 2, 0, 0, 0, 2, 1, 0, 3, 0, 0, 1, 1, 2, 0, 1, 2, 0, 1, 2, 0, 2, 2, 0, 1, 0, 0, 4, 1, 1, 1, 1, 0, 0, 3, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 4, 0, 0, 2, 0, 0, 2, 0, 0, 0, 1, 1, 3, 2, 0, 0, 2, 0, 3, 1, 1, 1, 0, 0, 4, 0, 0, 0, 1, 3, 1, 2, 0, 3, 0, 0, 1, 0, 0, 2, 0, 1, 2, 1, 1, 2, 3, 0, 2, 2, 0, 1, 2, 1, 0, 1, 0, 1, 0, 1, 3, 1, 2, 3, 3, 1, 1, 4, 3, 0, 0, 0, 0, 1, 3, 0, 0, 2, 0, 1, 2, 0, 3, 1, 2, 1, 1, 0, 3, 2, 0, 0, 2, 0, 1, 2, 2, 0, 1, 0, 0, 2, 0, 0, 2, 0, 4, 2, 0, 2, 2, 2, 0, 0, 2, 3, 0, 0, 0, 1, 1, 2, 0, 0, 3, 2, 1, 2, 1, 2, 0, 4, 0, 0, 1, 0, 1, 2, 1, 3, 0, 1, 0, 1, 2, 3, 3, 2, 1, 3, 0, 0, 3, 0, 0, 4, 1, 1, 0, 1, 2, 3, 0, 2, 3, 0, 3, 3, 1, 3, 2, 3, 3, 0, 1, 2, 1, 0, 4, 0, 1, 2, 2, 2, 1, 1, 1, 0, 1, 2, 0, 2, 1, 0, 1, 1, 1, 1, 2, 0, 2, 2, 4, 1, 2, 3, 4, 1, 2, 0, 1, 2, 2, 2, 2, 2, 0, 2, 0, 2, 4, 0, 2, 1, 2, 4, 1, 2, 0, 4, 0, 2, 1, 1, 3, 3, 1, 2, 1, 3, 0, 3, 2, 1, 1, 0, 1, 3, 4, 2, 0, 1, 1, 1, 1, 3, 5, 5, 3, 1, 4, 0, 0, 4, 1, 2, 4, 4, 1, 0, 1, 2, 2, 4, 2, 3, 2, 0, 1, 2, 1, 1, 0, 4, 2, 1, 4, 1, 0, 1, 0, 3, 1, 0, 2, 1, 2, 2, 0, 0, 1, 2, 2, 1, 2, 2, 1, 1, 2, 0, 3, 1, 1, 0, 0, 0, 2, 3, 2, 3, 3, 1, 1, 1, 3, 0, 1, 2, 3, 1, 2, 2, 1, 1, 3, 3, 3, 1, 1, 0, 4, 2, 1, 0, 1, 5, 2, 2, 3, 3, 2, 2, 1, 2, 2, 5]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>470 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "0    1\n",
       "1    0\n",
       "2    3\n",
       "3    0\n",
       "4    1\n",
       "..  ..\n",
       "465  2\n",
       "466  1\n",
       "467  2\n",
       "468  2\n",
       "469  5\n",
       "\n",
       "[470 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def carbBinMatrix(carbMin, carbMax, carbMatrix):\n",
    "    binMatrix = []\n",
    "    for i in carbMatrix:\n",
    "        if i >= carbMin and i <= carbMin + 20:\n",
    "            binMatrix.append(0)\n",
    "        if i >= carbMin + 21 and i <= carbMin + 40:\n",
    "            binMatrix.append(1)\n",
    "        if i >= carbMin + 41 and i <= carbMin + 60:\n",
    "            binMatrix.append(2)\n",
    "        if i >= carbMin + 61 and i <= carbMin + 80:\n",
    "            binMatrix.append(3)\n",
    "        if i >= carbMin + 81 and i <= carbMin + 100:\n",
    "            binMatrix.append(4)\n",
    "        if i >= carbMin + 100 and i <= carbMin + 120:\n",
    "            binMatrix.append(5)\n",
    "    return binMatrix\n",
    "\n",
    "binMatrix = carbBinMatrix(carbMin, carbMax, carbMatrix)\n",
    "print(binMatrix)\n",
    "\n",
    "carbdf = pd.DataFrame(binMatrix)\n",
    "carbdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80580c1",
   "metadata": {},
   "source": [
    "# Feature Extraction 0\n",
    "Extarcting Power Spectral Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ba272cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating PSD for each value of P\n",
    "from scipy import signal\n",
    "\n",
    "def extarctPSD(meal_Matrix):\n",
    "    psd1 = []\n",
    "    psd2 = []\n",
    "    psd3 = []\n",
    "    for i in meal_Matrix:\n",
    "        f, pxx = signal.periodogram(i)\n",
    "        psd1.append(round(np.mean(pxx[0:5]), 3))\n",
    "        psd2.append(round(np.mean(pxx[5:10]), 3))\n",
    "        psd3.append(round(np.mean(pxx[10:16]), 3))\n",
    "    return psd1, psd2, psd3\n",
    "\n",
    "psd1, psd2, psd3 = extarctPSD(meal_Matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c8057c",
   "metadata": {},
   "source": [
    "# Feature Extraction I\n",
    "\n",
    "Extracting Interquartile Range\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31b6f2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting iqr for all values of P\n",
    "from scipy.stats import iqr\n",
    "\n",
    "def extractIQR(meal_Matrix):\n",
    "    iqr_List = []\n",
    "    for i in range(len(meal_Matrix)):\n",
    "        val = iqr(meal_Matrix[i])\n",
    "        iqr_List.append(val)\n",
    "    return iqr_List\n",
    "\n",
    "iqr_List = extractIQR(meal_Matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872a5dfb",
   "metadata": {},
   "source": [
    "# Feature Extraction II\n",
    "\n",
    "Entropy for all P values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63982b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting Entropy for all P values\n",
    "from scipy.stats import entropy\n",
    "\n",
    "def extractEntropy(meal_Matrix):\n",
    "    entropy_List = []\n",
    "    for i in range(len(meal_Matrix)):\n",
    "        val, count = np.unique(meal_Matrix[i], return_counts = True)\n",
    "        entropy_List.append(round(entropy(count, None), 3))\n",
    "    return entropy_List\n",
    "        \n",
    "entropy_List = extractEntropy(meal_Matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568f2131",
   "metadata": {},
   "source": [
    "# Feature Extraction III\n",
    "Extracting peaks and frequencies unsinf FFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99790a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting FFT values\n",
    "def extractFFTValues(meal_Matrix):\n",
    "    freq2 = []\n",
    "    freq3 = []\n",
    "    freq1 = []\n",
    "    freq4 = []\n",
    "    freq5 = []\n",
    "    freq6 = []\n",
    "    for i in range(len(meal_Matrix)):\n",
    "        CGM_temp = meal_Matrix[i]\n",
    "        fft = sp.fftpack.fft(CGM_temp)\n",
    "        amp = np.abs(fft)\n",
    "        psd = amp ** 2\n",
    "        freq = sp.fftpack.fftfreq(len(CGM_temp), 1)\n",
    "    \n",
    "        #Sorting and finding max values\n",
    "        amp_sort = sorted(amp)\n",
    "        amp_sorted = []\n",
    "        [amp_sorted.append(x) for x in amp_sort if x not in amp_sorted]\n",
    "        \n",
    "        pos_1, pos_2, pos_3 = amp_sorted[-2], amp_sorted[-3], amp_sorted[-4]\n",
    "        pos_4, pos_5, pos_6 = amp_sorted[-5], amp_sorted[-6], amp_sorted[-7]\n",
    "\n",
    "        #checking for peak index by position\n",
    "        peak_1, peak_2 = np.where(amp == pos_1), np.where(amp == pos_2)\n",
    "        peak_3, peak_4 = np.where(amp == pos_3), np.where(amp == pos_4)\n",
    "        peak_5, peak_6 = np.where(amp == pos_5), np.where(amp == pos_6)\n",
    "        \n",
    "        \n",
    "        #getting peak indices\n",
    "        peak_index1, peak_index2 = peak_1[0][0], peak_2[0][0]\n",
    "        peak_index3, peak_index4 = peak_3[0][0], peak_4[0][0]\n",
    "        peak_index5, peak_index6 = peak_5[0][0], peak_6[0][0]\n",
    "        \n",
    "        #peak freq values\n",
    "        freq_1, freq_2 = freq[peak_index1], freq[peak_index2]\n",
    "        freq_3, freq_4 = freq[peak_index3], freq[peak_index4]\n",
    "        freq_5, freq_6 = freq[peak_index5], freq[peak_index6]\n",
    "        \n",
    "        \n",
    "        #adding into list\n",
    "        freq2.append(round(freq_2, 3))\n",
    "        freq3.append(round(freq_3, 3))\n",
    "        freq1.append(round(freq_1, 3))\n",
    "        freq4.append(round(freq_4, 3))\n",
    "        freq5.append(round(freq_5, 3))\n",
    "        freq6.append(round(freq_6, 3))\n",
    "    return freq1, freq2, freq3, freq4, freq5, freq6\n",
    "\n",
    "freq1, freq2, freq3, freq4, freq5, freq6 = extractFFTValues(meal_Matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b35d970",
   "metadata": {},
   "source": [
    "# Feature Extraction IV\n",
    "\n",
    "Extarcting derivatives and double derivatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1882f174",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting first derivative\n",
    "def extractFirstDervative(meal_Matrix):\n",
    "    firstDervative_min = []\n",
    "    firstDervative_max = []\n",
    "    firstDervative_mean = []\n",
    "    for i in range(len(meal_Matrix)):\n",
    "        CGMmax = max(meal_Matrix[i])\n",
    "        CGMmax_Index = meal_Matrix[i].index(CGMmax)\n",
    "        diff = np.diff(meal_Matrix[i][:CGMmax_Index], 1)\n",
    "        diff = diff.tolist()\n",
    "        if len(diff) > 0:\n",
    "            diff_avg = np.mean(diff)\n",
    "            diff_max = max(diff)\n",
    "            diff_min = min(diff)\n",
    "        else:\n",
    "            diff_avg = 0\n",
    "            diff_max = 0\n",
    "            diff_min = 0\n",
    "        firstDervative_mean.append(round(diff_avg, 2))\n",
    "        firstDervative_max.append(diff_max)\n",
    "        firstDervative_min.append(diff_min)\n",
    "    return firstDervative_mean, firstDervative_max, firstDervative_min\n",
    "\n",
    "#Extracting second derivative\n",
    "def extractSecondDervative(meal_Matrix):\n",
    "    secondDervative_mean = []\n",
    "    secondDervative_max = []\n",
    "    secondDervative_min = []\n",
    "    for i in range(len(meal_Matrix)):\n",
    "        CGMmax = max(meal_Matrix[i])\n",
    "        CGMmax_Index = meal_Matrix[i].index(CGMmax)\n",
    "        diff = np.diff(meal_Matrix[i][0:CGMmax_Index], 2)\n",
    "        if len(diff) > 0:\n",
    "            diff_avg = np.mean(diff)\n",
    "            diff_max = max(diff)\n",
    "            diff_min = min(diff)\n",
    "        else:\n",
    "            diff_avg = 0\n",
    "            diff_max = 0\n",
    "            diff_min = 0\n",
    "        secondDervative_mean.append(round(diff_avg, 2))\n",
    "        secondDervative_max.append(diff_max)\n",
    "        secondDervative_min.append(diff_min)\n",
    "    return secondDervative_mean, secondDervative_max, secondDervative_min\n",
    "\n",
    "firstDervative_mean, firstDervative_max, firstDervative_min  = extractFirstDervative(meal_Matrix)\n",
    "secondDervative_mean, secondDervative_max, secondDervative_min = extractSecondDervative(meal_Matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767275f1",
   "metadata": {},
   "source": [
    "# Creating Meal Feature Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4663c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Feature Matrices:\n",
    "\n",
    "data =[]\n",
    "for i in range(len(meal_Matrix)):\n",
    "    data.append({\n",
    "    'Interquartile Range' : iqr_List[i],\n",
    "    'Entropy' : entropy_List[i],\n",
    "    'PSD I' : psd1[i],\n",
    "    'PSD II' : psd2[i],\n",
    "    'PSD III' : psd3[i],\n",
    "    'Frequency I' : freq1[i],\n",
    "    'Frequency II' : freq2[i],\n",
    "    'Frequency III' : freq3[i],\n",
    "    'Frequency IV' : freq4[i],\n",
    "    'Frequency V' : freq5[i],\n",
    "    'Frequency VI' : freq6[i],\n",
    "    'Velocity Mean' : firstDervative_mean[i],\n",
    "    'Velocity Max' : firstDervative_max[i],\n",
    "    'Velocity Min' : firstDervative_min[i],\n",
    "    'Accelaration Mean' : secondDervative_mean[i],\n",
    "    'Accelaration Max' : secondDervative_max[i],\n",
    "    'Accelaration Min' : secondDervative_min[i]\n",
    "        })\n",
    "\n",
    "mealData_Feature_Matrix = pd.DataFrame(data)\n",
    "meal_feature_matrix = mealData_Feature_Matrix.reset_index().drop(columns = 'index')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33be65a5",
   "metadata": {},
   "source": [
    "# Normalizing the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe66df32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "meal_feature_matrix.iloc[:,:] = scaler.fit_transform(meal_feature_matrix.iloc[:,:].to_numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946cc991",
   "metadata": {},
   "source": [
    "# K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dfc15c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First find the optimal number of clusters by using elbow method\n",
    "eachCluster = []\n",
    "for i in range(1,15):\n",
    "    kmeans = KMeans(n_clusters=i, init = 'k-means++', max_iter = 300, n_init= 10)\n",
    "    kmeans.fit(meal_feature_matrix[0::].values)\n",
    "    eachCluster.append(kmeans.inertia_)\n",
    "\n",
    "#plt.plot(range(1,15), eachCluster)\n",
    "#plt.title(\"Cluster Efficiency\")\n",
    "#plt.xlabel(\"Number of Clusters\")\n",
    "#plt.ylabel(\"Each Cluster\")\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f603fde6",
   "metadata": {},
   "source": [
    "Based on the graph above it is evident that having 6 clusters will give optimal results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e40a6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating 6 clusters for the dataset\n",
    "kmeans = KMeans(n_clusters = 6, max_iter=300, n_init= 10)\n",
    "cluster_KMeans = kmeans.fit_predict(meal_feature_matrix)\n",
    "labels = kmeans.predict(meal_feature_matrix)\n",
    "\n",
    "kmeans_matrix = meal_feature_matrix.copy()\n",
    "kmeans_matrix['Cluster'] = pd.Series(labels, index = meal_feature_matrix.index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac145c5",
   "metadata": {},
   "source": [
    "# KMeans Cluster Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ac93583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth     0     1     2     3     4    5\n",
      "Clusters                                       \n",
      "0             32.0  24.0  15.0   7.0   6.0  1.0\n",
      "1              8.0   8.0  17.0   8.0   4.0  1.0\n",
      "2             53.0  39.0  39.0  22.0  10.0  1.0\n",
      "3              8.0   7.0   5.0   3.0   3.0  0.0\n",
      "4              3.0   8.0   9.0   2.0   1.0  0.0\n",
      "5             44.0  43.0  25.0  10.0   3.0  1.0\n"
     ]
    }
   ],
   "source": [
    "#Calculating SSE\n",
    "cluster_centers = [kmeans_matrix[kmeans.labels_ == i].mean(axis=0) for i in range(6)]\n",
    "\n",
    "sseKMeans = [0,0,0,0,0,0]\n",
    "for point, label in zip(kmeans_matrix.values, kmeans.labels_):\n",
    "    sseKMeans[label] += np.square(point - cluster_centers[label]).sum()\n",
    "    \n",
    "KMeans_SSE = round(sum(sseKMeans), 3)\n",
    "    \n",
    "#First creating confusion matrix for calculating Purity and Entropy\n",
    "tempdf = pd.DataFrame()\n",
    "tempdf['Ground Truth'] = carbdf\n",
    "tempdf['Clusters'] = list(labels)\n",
    "\n",
    "cf_matrix = pd.pivot_table(tempdf, index='Clusters', columns='Ground Truth', aggfunc=len)\n",
    "\n",
    "cf_matrix.fillna(value = 0, inplace = True)\n",
    "\n",
    "#temp df to store total values\n",
    "cf_matrix_temp = cf_matrix.copy()\n",
    "\n",
    "cf_matrix_temp['Total'] = cf_matrix.sum(axis=1)\n",
    "total = cf_matrix_temp['Total']\n",
    "\n",
    "print(cf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c23892e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating Entropy and Purity\n",
    "entropyKmeans = []\n",
    "purityKmeans = []\n",
    "for row, rowData in cf_matrix_temp.iterrows():\n",
    "    entropy = 0\n",
    "    purity = []\n",
    "    for i in rowData[0:5]:\n",
    "        if i > 0:\n",
    "            val = round(i/rowData.iloc[6] , 3)\n",
    "            purity.append(val)\n",
    "            entropy += val + math.log2(val)\n",
    "    entropyKmeans.append(-entropy)\n",
    "    purityKmeans.append(max(purity))\n",
    "    \n",
    "#calculating total entropy, purity and sse\n",
    "KMeans_Entropy = 0\n",
    "KMeans_Purity = 0\n",
    "val1 = 0\n",
    "val2 = 0\n",
    "for i in range(len(entropyKmeans)):\n",
    "    val1 += total.values[i] * entropyKmeans[i]\n",
    "    val2 += total.values[i] * purityKmeans[i]\n",
    "KMeans_Entropy = round((val1/len(meal_feature_matrix)), 3)\n",
    "KMeans_Purity = round((val2/len(meal_feature_matrix)), 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fb9c73",
   "metadata": {},
   "source": [
    "# DBScan Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33dc316e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Execute dbscan for meal_feature_matrix\n",
    "dbscan = DBSCAN(eps=0.211, min_samples=5).fit(meal_feature_matrix)\n",
    "cluster_DBScan = dbscan.fit_predict(meal_feature_matrix)\n",
    "\n",
    "cluster_labels = np.unique(dbscan.labels_)\n",
    "cluster_labels = labels[1:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979e3108",
   "metadata": {},
   "source": [
    "# DBScan Cluster Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e3afc073",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating SSE\n",
    "dbscan_matrix = meal_feature_matrix.copy()\n",
    "dbscan_matrix['db-cluster'] = dbscan.labels_\n",
    "\n",
    "cluster_num = len(set(dbscan.labels_)) -(1 if -1 in dbscan.labels_ else 0)\n",
    "cluster_centers_dbs = [dbscan_matrix[dbscan.labels_ == i].mean(axis=0) for i in range(cluster_num +1)]\n",
    "\n",
    "sseDBScan = [0,0,0,0,0,0,0,0]\n",
    "for point, label in zip(dbscan_matrix.values, dbscan.labels_):\n",
    "    sseDBScan[label] += np.square(point - cluster_centers[label]).sum()\n",
    "\n",
    "sseDBScan = sseDBScan[0:6]\n",
    "\n",
    "DBScan_SSE = round(sum(sseDBScan), 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9583c4dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth     0     1     2     3    4    5\n",
      "Clusters                                      \n",
      "0             35.0  32.0  22.0  12.0  6.0  1.0\n",
      "1              3.0   1.0   0.0   0.0  1.0  0.0\n",
      "2              4.0   4.0   3.0   1.0  0.0  0.0\n",
      "3              2.0   1.0   2.0   0.0  0.0  0.0\n",
      "4              2.0   1.0   0.0   1.0  1.0  0.0\n",
      "5              2.0   3.0   0.0   0.0  0.0  0.0\n"
     ]
    }
   ],
   "source": [
    "#Creating Confusion Matrix\n",
    "tempdf = pd.DataFrame()\n",
    "tempdf['Ground Truth'] = carbdf\n",
    "tempdf['Clusters'] = list(dbscan.labels_)\n",
    "\n",
    "dbs_matrix = pd.pivot_table(tempdf, index='Clusters', columns='Ground Truth', aggfunc=len)\n",
    "\n",
    "dbs_matrix.fillna(value = 0, inplace = True)\n",
    "dbs_matrix = dbs_matrix.drop(dbs_matrix.index[0])\n",
    "\n",
    "#temp df to store total values\n",
    "dbs_matrix_temp = dbs_matrix.copy()\n",
    "dbs_matrix_temp['Total'] = dbs_matrix_temp.sum(axis=1)\n",
    "\n",
    "total1 = dbs_matrix_temp['Total']\n",
    "\n",
    "print(dbs_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3cced1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating Entropy and Purity\n",
    "entropyDBScan = []\n",
    "purityDBScan = []\n",
    "for row, rowData in dbs_matrix_temp.iterrows():\n",
    "    entropy = 0\n",
    "    purity = []\n",
    "    for i in rowData[0:5]:\n",
    "        if i > 0:\n",
    "            val = round(i/rowData.iloc[6] , 3)\n",
    "            purity.append(val)\n",
    "            entropy += val + math.log2(val)\n",
    "    entropyDBScan.append(-entropy)\n",
    "    purityDBScan.append(max(purity))\n",
    "\n",
    "#calculating total entropy, purity and sse\n",
    "DBScan_Entropy = 0\n",
    "DBScan_Purity = 0\n",
    "val1 = 0\n",
    "val2 = 0\n",
    "for i in range(len(purityDBScan)):\n",
    "    val1 += total1.values[i] * entropyDBScan[i]\n",
    "    val2 += total1.values[i] * purityDBScan[i]\n",
    "DBScan_Entropy = round((val1/len(meal_feature_matrix)), 3)\n",
    "DBScan_Purity = round((val2/len(meal_feature_matrix)), 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4db6a0",
   "metadata": {},
   "source": [
    "# Creating Results.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b49c7cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [KMeans_SSE, DBScan_SSE, KMeans_Entropy, DBScan_Entropy, KMeans_Purity, DBScan_Purity]\n",
    "resultsdf = pd.DataFrame(results).T\n",
    "\n",
    "resultsdf.to_csv('Results.csv', header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ecceb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5ddcf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
